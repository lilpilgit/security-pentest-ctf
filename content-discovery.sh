#!/bin/sh

# This script try different method to do some content discovery

# directory and files
#TODO
# 1) robots.txt
# 2) favicon curl https://static-labs.tryhackme.cloud/sites/favicon/images/favicon.ico | md5sum
#    curl https://static-labs.tryhackme.cloud/sites/favicon/images/favicon.ico | md5sum
# 3) sitemap.xml  http://10.10.86.155/sitemap.xml
# 4) header curl -v http://10.10.86.155
# 5) google hacking/dorking 
site
	site:tryhackme.com
	returns results only from the specified website address
  site:*.example.com, by using this filter we can get all subdomains of a particular domain.
inurl
	inurl:admin
	returns results that have the specified word in the URL
filetype
	filetype:pdf
	returns results which are a particular file extension
intitle
	intitle:admin
	returns results that contain the specified word in the title

# ffuf -w /usr/share/seclists/Discovery/Web-Content/common.txt -u http://10.10.86.155/FUZZ -s
!!much more slow!! # dirb http://10.10.86.155 /usr/share/seclists/Discovery/Web-Content/common.txt -S 
# gobuster dir  --url http://10.10.86.155 -w /usr/share/seclists/Discovery/Web-Content/common.txt --no-error

# DNS reconaissance

dnsrecon -d {DOMAIN_NAME}

# for DNS not publicly hosted but private DNS 

ffuf -w {WORDLIST} -H "Host: FUZZ.acmeitsupport.thm" -u http://MACHINE-IP -fs {SIZE}

# SUBDOMAIN reconaissance

OSINT -Sublist3r:

sublis3r -d {DOMAIN_NAME}







